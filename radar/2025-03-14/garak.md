---
title: "Garak"
ring: trial
segment: evaluation
tags: [evaluation, security]
---

[Garak](https://github.com/NVIDIA/garak) is NVIDIA's open-source security testing toolkit for evaluating Large Language Models (LLMs). It provides a comprehensive suite of tests to assess model vulnerabilities, detect potential security issues, and ensure robustness across different scenarios.

## Key Features

- Extensive test suite for LLM vulnerabilities
- Automated prompt injection detection
- Model robustness assessment
- Customizable testing scenarios

## Business Value

- Early detection of security risks
- Compliance with AI security standards
- Protection against model exploitation
- Enhanced AI system trustworthiness


## Resources

- [Documentation](https://docs.garak.ai/garak)
- [GitHub Repository](https://github.com/leondz/garak)

## Related AI Radar Topics

- [OWASP LLM Top 10](/architecture-pattern/owasp_llm_top_10/)
- [Prompt Injection Awareness](/architecture-pattern/prompt_injection_awareness/)
